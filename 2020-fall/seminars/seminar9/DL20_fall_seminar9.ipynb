{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "DL20-fall-seminar9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15BkQrrWYFm7"
      },
      "source": [
        "# Нейросети и вероятностные модели\n",
        "\n",
        "**Разработчик: Алексей Умнов**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X4T4_l3YFm_"
      },
      "source": [
        "# Авторегрессионные модели\n",
        "\n",
        "На этом семинаре мы поработаем с авторегрессионными моделями на примере архитектуры PixelCNN. Мы обучим модель для задачи генерации изображений и для задачи дорисовывания недостающих частей изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZa_hAENYFnB"
      },
      "source": [
        "### LCD digits dataset\n",
        "\n",
        "В качестве примера мы возьмем датасет из простых LCD-цифр. Ниже приведен код, который его загружает и рисует примеры сэмплов.\n",
        "\n",
        "Источник датасета: https://gist.github.com/benjaminwilson/b25a321f292f98d74269b83d4ed2b9a8#file-lcd-digits-dataset-nmf-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXtp9nFhYFnD"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY1_pHlQYFnH"
      },
      "source": [
        "from utils import LcdDigits, IMAGE_WIDTH, IMAGE_HEIGHT\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "train_dataset = LcdDigits(BATCH_SIZE * 50)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "def show_as_image(image, figsize=(10, 5)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    \n",
        "def batch_images_to_one(batches_images):\n",
        "    n_square_elements = int(np.sqrt(batches_images.shape[0]))\n",
        "    rows_images = np.split(np.squeeze(batches_images), n_square_elements)\n",
        "    return np.vstack([np.hstack(row_images) for row_images in rows_images])\n",
        "\n",
        "for batch, _ in train_loader:\n",
        "    show_as_image(batch_images_to_one(batch[:25]), figsize=(10, 10))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEVaGINYYFnL"
      },
      "source": [
        "Здесь специально выбран простой датасет, так как вероятностные модели обычно требуют больших ресурсов. Также обратите внимание, что хотя данные очень простые (фактически всего 10 разных сэмплов), они находятся в пространстве значительно большей размерности ($2^{8 \\times 13}$). Мы будем подавать модели сырые пиксели на вход, и будем хотеть, чтобы она нашла в них правильные зависимости и научилась строить только валидные изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJzlYXm8YFnM"
      },
      "source": [
        "### PixelCNN\n",
        "\n",
        "Коротко вспомним, что такое PixelCNN. Авторегрессионные модели в общем виде моделируют распределения на векторах $x = (x_1, \\ldots, x_N)$ в виде:\n",
        "\n",
        "$$\n",
        "    p(x) = \\prod_{i=1}^{N} p(x_i \\mid x_1, \\ldots, x_{i-1}).\n",
        "$$\n",
        "\n",
        "Распределения $p(x_i \\mid x_1, \\ldots, x_{i-1})$ можно моделировать при помощи нейронных сетей, которые получают на вход значения $x_1, \\ldots, x_{i-1}$ и выдают распределение вероятностей для значений $x_i$. Так как входов здесь переменное число, можно использовать рекуррентные сети (например, PixelRNN), но неплохо работает и более простая модель &mdash; PixelCNN, &mdash; которая подает на вход не все значения $x_1, \\ldots, x_{i-1}$, а только соседние на некотором расстоянии с помощью сверточных слоев.\n",
        "\n",
        "![pixelcnn](pixelcnn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rGLrAqSYFnN"
      },
      "source": [
        "Для того, чтобы для данного пикселя подавать на вход только значения идущие ранее, вместо обычных сверток нужно использовать маскированные свертки. Напишите недостающий код, чтобы создать соответствующие маски и потом сделайте из них слой для pytorch. Такие слои можно добавлять последовательно, сохраняя корректные зависимости, при этом во всех слоях кроме первого можно использовать центральный пиксель. У вас должны получаться вот такие маски (с `include_center=False` и с `include_center=True` соответственно):\n",
        "\n",
        "![](mask_with_center.png)\n",
        "![](mask_no_center.png)\n",
        "\n",
        "Hint: можно умножить на маску не входы, а веса."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn8qDNBbYFnO"
      },
      "source": [
        "def causal_mask(width, height, starting_point):\n",
        "    \n",
        "    # YOUR CODE\n",
        "    \n",
        "    return mask\n",
        "\n",
        "def conv_mask(height, width, include_center=False):\n",
        "    return 1.0 * causal_mask(\n",
        "        width, height, \n",
        "        starting_point=(height//2, width//2 + include_center - 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eASPxssYFnS"
      },
      "source": [
        "class MaskedConv2d(nn.Conv2d):\n",
        "    def __init__(self, include_center, *args, **kwargs):\n",
        "        \n",
        "    # YOUR CODE\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQFi3EZpYFnW"
      },
      "source": [
        "Теперь соберите сеть с несколькими слоями маскированных сверток и обучите ее.\n",
        "\n",
        "Hint 1: в задаче хорошо помогает сверточный слой 1x1 в конце.\n",
        "\n",
        "Hint 2: если ошибиться и нарушить казуальность (т.е. сделать зависимости вперед), то обучаться будет хорошо, а генерировать плохо."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpmWX_4hO7ON"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NalcDVxPYFnX"
      },
      "source": [
        "class PixelCNN(nn.Module):\n",
        "    N_PIXELS_OUT = 2 # binary 0/1 pixels\n",
        "    \n",
        "    def __init__(self, n_channels, kernel_size, padding):\n",
        "                 \n",
        "    # YOUR CODE\n",
        "        \n",
        "    def forward(self, x):\n",
        "        pixel_logits = self.layers(x)\n",
        "        return pixel_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MOsZ5dyYFna"
      },
      "source": [
        "N_EPOCHS = 25\n",
        "LR = 0.005\n",
        "\n",
        "cnn = PixelCNN(n_channels=4, kernel_size=7, padding=3)\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nek5rwLIYFne"
      },
      "source": [
        "Обратите внимание, что полученной сети достаточно подать на вход изображение, и на выходе получится распределение для значений каждого пикселя. Осталось только минимизировать кросс-энтропию этих значений и пикселей примеров в выборке. В случае успеха итоговая кросс-энтропия будет около 0.02."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO-RlnLEYFnf"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # YOUR CODE\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print ('Epoch [%d/%d], Loss: %.4f' \n",
        "                   %(epoch+1, N_EPOCHS, loss.data.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU-ZL85-YFnj"
      },
      "source": [
        "При генерации изображений можно начинать с пустого изображения, а можно подавать какие-то начальные пиксели. Допишите функцию генерации и проверьте ее для задачи генерации (на вход пустое изображения) и для задачи дорисовывания (на вход - верхняя часть изображения).\n",
        "\n",
        "У вас должны получиться разумные изображения цифр, допускается небольшая доля \"плохих\" изображений.\n",
        "\n",
        "*Упражнение:* почему при одинаковых пустых входных изображениях получаются разные изображения на выходе?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1iEljgXO-iz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1o9I-9iYFnk"
      },
      "source": [
        "def generate_samples(n_samples, starting_point=(0, 0), starting_image=None):\n",
        "\n",
        "    samples = torch.from_numpy(\n",
        "        starting_image if starting_image is not None else \n",
        "        np.zeros((n_samples * n_samples, 1, IMAGE_HEIGHT, IMAGE_WIDTH))).float()\n",
        "\n",
        "    cnn.train(False)\n",
        "    \n",
        "    # YOUR CODE\n",
        "    \n",
        "    return samples.numpy()\n",
        "\n",
        "\n",
        "show_as_image(batch_images_to_one(generate_samples(n_samples=10)), figsize=(10, 20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZPqF6x_YFno"
      },
      "source": [
        "from utils import random_digits\n",
        "\n",
        "n_images = 10\n",
        "starting_point = (4, 3)\n",
        "\n",
        "mask = causal_mask(IMAGE_HEIGHT, IMAGE_WIDTH, starting_point)\n",
        "\n",
        "starting_images = digits_list = [random_digits(fixed_label=d)[0] for d in range(10)]\n",
        "batch_starting_images = np.expand_dims(np.stack([i * mask for i in starting_images] * n_images), axis=1)\n",
        "\n",
        "samples = generate_samples(n_images, starting_image=batch_starting_images, starting_point=starting_point)\n",
        "\n",
        "show_as_image(np.hstack([(1 + mask) * i for i in starting_images]), figsize=(10, 10))\n",
        "\n",
        "show_as_image(\n",
        "    batch_images_to_one((samples * (1 + mask))),\n",
        "    figsize=(10, 20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEj0kKlPYFnr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}